"""
å¯¼å…¥ Twitter å†å²å¸–å­
æ”¯æŒ Twitter æ•°æ®å¯¼å‡ºæ–‡ä»¶
"""
import json
import os
import zipfile
from typing import List, Dict, Any
from update_data import load_existing_data, save_to_jsonl
from search import extract_urls_from_text, should_exclude_url

# Twitter é…ç½®
TWITTER_USERNAME = ""  # ä½ çš„ Twitter ç”¨æˆ·åï¼ˆå¯é€‰ï¼Œç”¨äºç”Ÿæˆé“¾æ¥ï¼‰


def extract_twitter_zip(zip_path: str, extract_to: str = "twitter_export") -> str:
    """è§£å‹ Twitter å¯¼å‡º ZIP æ–‡ä»¶"""
    if not os.path.exists(zip_path):
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {zip_path}")
    
    # åˆ›å»ºè§£å‹ç›®å½•
    os.makedirs(extract_to, exist_ok=True)
    
    # è§£å‹æ–‡ä»¶
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)
    
    print(f"âœ… å·²è§£å‹åˆ°: {extract_to}")
    return extract_to


def parse_twitter_json(json_path: str) -> List[Dict[str, Any]]:
    """è§£æ Twitter JSON æ–‡ä»¶"""
    items = []
    
    with open(json_path, 'r', encoding='utf-8') as f:
        content = f.read()
        
        # Twitter å¯¼å‡ºæ–‡ä»¶å¯èƒ½æ˜¯ JavaScript æ ¼å¼ï¼Œéœ€è¦å¤„ç†
        # æ ¼å¼é€šå¸¸æ˜¯: window.YTD.tweets.part0 = [ ... ];
        if 'window.YTD.tweets.part' in content:
            # æå– JSON éƒ¨åˆ†
            start = content.find('[')
            end = content.rfind(']') + 1
            if start != -1 and end != 0:
                json_str = content[start:end]
                data = json.loads(json_str)
            else:
                print("âš ï¸  æ— æ³•è§£æ Twitter å¯¼å‡ºæ–‡ä»¶æ ¼å¼")
                return []
        else:
            # æ ‡å‡† JSON æ ¼å¼
            data = json.load(f)
    
    # å¤„ç†æ•°æ®
    for tweet_data in data:
        # Twitter å¯¼å‡ºæ ¼å¼: { "tweet": { ... } }
        if isinstance(tweet_data, dict) and 'tweet' in tweet_data:
            tweet = tweet_data['tweet']
        elif isinstance(tweet_data, dict):
            tweet = tweet_data
        else:
            continue
        
        # æå–æ¨æ–‡ä¿¡æ¯
        full_text = tweet.get('full_text', '') or tweet.get('text', '')
        if not full_text:
            continue
        
        # æå–æ—¥æœŸ
        created_at = tweet.get('created_at', '')
        
        # æå–æ¨æ–‡ ID
        tweet_id = tweet.get('id_str') or str(tweet.get('id', ''))
        
        # æå–é“¾æ¥ï¼ˆä» entities ä¸­æå–ï¼‰
        content_urls = []
        entities = tweet.get('entities', {})
        urls = entities.get('urls', [])
        for url_obj in urls:
            # ä¼˜å…ˆä½¿ç”¨å±•å¼€çš„ URL
            url = url_obj.get('expanded_url') or url_obj.get('url', '')
            if url and not should_exclude_url(url) and url not in content_urls:
                content_urls.append(url)
        
        # ä»çº¯æ–‡æœ¬ä¸­æå– URLï¼ˆè¡¥å……æå–ï¼Œå·²åŒ…å«è¿‡æ»¤ï¼‰
        urls_from_text = extract_urls_from_text(full_text)
        for url in urls_from_text:
            if url not in content_urls:
                content_urls.append(url)
        
        # ç”Ÿæˆ Twitter é“¾æ¥
        username = TWITTER_USERNAME or tweet.get('user', {}).get('screen_name', '')
        twitter_link = f"https://twitter.com/{username}/status/{tweet_id}" if username and tweet_id else ""
        
        # åˆ¤æ–­æ¨æ–‡ç±»å‹
        in_reply_to_status_id = tweet.get('in_reply_to_status_id_str')
        is_reply = bool(in_reply_to_status_id)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è½¬å‘ï¼ˆretweeted_status å­—æ®µå­˜åœ¨ï¼‰
        is_retweet = 'retweeted_status' in tweet
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¼•ç”¨æ¨æ–‡ï¼ˆquoted_status å­—æ®µå­˜åœ¨ï¼‰
        is_quote = 'quoted_status' in tweet
        
        # æ£€æŸ¥å†…å®¹æ˜¯å¦ä»¥ RT @ å¼€å¤´ï¼ˆæ‰‹åŠ¨è½¬å‘ï¼‰
        is_manual_rt = full_text.strip().startswith('RT @')
        
        # ç¡®å®šç±»å‹
        if is_retweet:
            tweet_type = "retweet"
            title_suffix = " (Retweet)"
        elif is_quote:
            tweet_type = "quote"
            title_suffix = " (Quote)"
        elif is_manual_rt:
            tweet_type = "retweet"  # æ‰‹åŠ¨è½¬å‘ä¹Ÿå½’ç±»ä¸º retweet
            title_suffix = " (Retweet)"
        elif is_reply:
            tweet_type = "reply"
            title_suffix = " (Reply)"
        else:
            tweet_type = "tweet"
            title_suffix = ""
        
        item = {
            "source": "twitter",
            "type": tweet_type,  # tweet, reply, retweet, quote
            "title": f"Twitter Post{title_suffix}",
            "content": full_text,
            "url": content_urls[0] if content_urls else "",  # ç¬¬ä¸€ä¸ªé“¾æ¥ï¼ˆå‘åå…¼å®¹ï¼‰
            "urls": content_urls,  # æ‰€æœ‰é“¾æ¥åˆ—è¡¨
            "tg_link": twitter_link,  # å¤ç”¨å­—æ®µå­˜å‚¨ Twitter é“¾æ¥
            "date": created_at,
            "id": int(tweet_id) if tweet_id.isdigit() else hash(tweet_id)
        }
        
        items.append(item)
    
    return items


def import_twitter_export(export_path: str) -> int:
    """å¯¼å…¥ Twitter å¯¼å‡ºæ–‡ä»¶"""
    print(f"ğŸ“¥ æ­£åœ¨å¯¼å…¥ Twitter æ•°æ®: {export_path}")
    
    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
    if export_path.endswith('.zip'):
        # è§£å‹ ZIP æ–‡ä»¶
        extract_dir = extract_twitter_zip(export_path)
        
        # æŸ¥æ‰¾ tweets.js æˆ– tweets.json æ–‡ä»¶
        tweets_file = None
        for root, dirs, files in os.walk(extract_dir):
            for file in files:
                if file.startswith('tweet') and (file.endswith('.js') or file.endswith('.json')):
                    tweets_file = os.path.join(root, file)
                    break
            if tweets_file:
                break
        
        if not tweets_file:
            # å°è¯•æŸ¥æ‰¾ data/tweets.js
            possible_paths = [
                os.path.join(extract_dir, 'data', 'tweets.js'),
                os.path.join(extract_dir, 'data', 'tweets.json'),
                os.path.join(extract_dir, 'tweets.js'),
                os.path.join(extract_dir, 'tweets.json'),
            ]
            for path in possible_paths:
                if os.path.exists(path):
                    tweets_file = path
                    break
        
        if not tweets_file:
            print("âŒ æœªæ‰¾åˆ° tweets.js æˆ– tweets.json æ–‡ä»¶")
            print("è¯·æ£€æŸ¥å¯¼å‡ºæ–‡ä»¶ç»“æ„")
            return 0
        
        print(f"ğŸ“„ æ‰¾åˆ°æ¨æ–‡æ–‡ä»¶: {tweets_file}")
    else:
        # ç›´æ¥æ˜¯ JSON æ–‡ä»¶
        tweets_file = export_path
    
    # è§£ææ¨æ–‡
    print("ğŸ“– æ­£åœ¨è§£ææ¨æ–‡...")
    new_items = parse_twitter_json(tweets_file)
    
    if not new_items:
        print("âŒ æœªæ‰¾åˆ°æ¨æ–‡æ•°æ®")
        return 0
    
    print(f"âœ… è§£æåˆ° {len(new_items)} æ¡æ¨æ–‡")
    
    # åŠ è½½ç°æœ‰æ•°æ®
    existing = load_existing_data()
    
    # åˆå¹¶æ•°æ®ï¼ˆå»é‡ï¼‰
    new_count = 0
    for item in new_items:
        item_id = item.get("id", 0)
        if item_id and item_id not in existing:
            existing[item_id] = item
            new_count += 1
    
    # ä¿å­˜
    save_to_jsonl(list(existing.values()))
    
    print(f"âœ… å·²å¯¼å…¥ {new_count} æ¡æ–°æ¨æ–‡ï¼ˆå…± {len(existing)} æ¡ï¼‰")
    
    return new_count


def main():
    import sys
    
    print("ğŸ¦ Twitter å†å²å¸–å­å¯¼å…¥å·¥å…·")
    print("=" * 50)
    print()
    
    if len(sys.argv) > 1:
        export_path = sys.argv[1]
    else:
        export_path = input("è¯·è¾“å…¥ Twitter å¯¼å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆZIP æˆ– JSONï¼‰: ").strip()
        if not export_path:
            print("âŒ æœªæä¾›æ–‡ä»¶è·¯å¾„")
            return
    
    if not os.path.exists(export_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {export_path}")
        return
    
    # å¯¼å…¥æ•°æ®
    new_count = import_twitter_export(export_path)
    
    if new_count > 0:
        print()
        push = input("æ˜¯å¦æ¨é€åˆ° GitHub? (y/n): ").strip().lower()
        if push == "y":
            from update_data import push_to_github
            push_to_github()
    
    print()
    print("âœ… å®Œæˆï¼ç°åœ¨å¯ä»¥åœ¨æœç´¢ç³»ç»Ÿä¸­æœç´¢ Twitter å†…å®¹äº†")


if __name__ == "__main__":
    main()

