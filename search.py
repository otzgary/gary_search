import json
import os
import re
from typing import List, Dict, Any

# æ•°æ®æ–‡ä»¶è·¯å¾„
TG_DATA_FILE = "ChatExport_2025-12-06/result.json"
DATA_FILE = "data.jsonl"

# Telegram é¢‘é“é…ç½®
# å¦‚æœé¢‘é“æ˜¯å…¬å¼€çš„ï¼Œè¯·åœ¨è¿™é‡Œè®¾ç½®é¢‘é“ç”¨æˆ·åï¼ˆä¾‹å¦‚: "yourchannel" æˆ– "@yourchannel"ï¼‰
# å¦‚æœé¢‘é“æ˜¯ç§æœ‰çš„ï¼Œç•™ç©ºå³å¯ï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨é¢‘é“ ID
TG_CHANNEL_USERNAME = "gary10x"  # å…¬å¼€é¢‘é“ç”¨æˆ·å


def extract_text_from_message(text_field: Any) -> str:
    """ä»æ¶ˆæ¯çš„ text å­—æ®µæå–çº¯æ–‡æœ¬å†…å®¹"""
    if isinstance(text_field, str):
        return text_field
    elif isinstance(text_field, list):
        result = []
        for item in text_field:
            if isinstance(item, str):
                result.append(item)
            elif isinstance(item, dict):
                # å¦‚æœæ˜¯é“¾æ¥æˆ–å…¶ä»–å®ä½“ï¼Œæå–æ–‡æœ¬
                if "text" in item:
                    result.append(item["text"])
        return "".join(result)
    return ""


def should_exclude_url(url: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ’é™¤æŸä¸ª URL"""
    if not url:
        return True
    
    url_lower = url.lower()
    
    # æ’é™¤ Twitter/X ç›¸å…³é“¾æ¥
    if any(domain in url_lower for domain in [
        'twitter.com', 'x.com', 't.co', 'twitter.com/i/web'
    ]):
        return True
    
    # æ’é™¤ Telegram é“¾æ¥
    if 't.me' in url_lower:
        return True
    
    return False


def extract_urls_from_text(text: str) -> List[str]:
    """ä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰ URLï¼Œå¹¶è¿‡æ»¤æ‰ä¸éœ€è¦çš„é“¾æ¥"""
    if not text:
        return []
    
    # URL æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
    url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+[^\s<>"{}|\\^`\[\].,;:!?]'
    urls = re.findall(url_pattern, text)
    
    # å»é‡å¹¶ä¿æŒé¡ºåºï¼ŒåŒæ—¶è¿‡æ»¤ä¸éœ€è¦çš„é“¾æ¥
    seen = set()
    unique_urls = []
    for url in urls:
        # æ’é™¤ Twitter/Telegram ç­‰ä¸éœ€è¦çš„é“¾æ¥
        if should_exclude_url(url):
            continue
        if url not in seen:
            seen.add(url)
            unique_urls.append(url)
    
    return unique_urls


def load_tg_messages() -> List[Dict[str, Any]]:
    """ä» Telegram å¯¼å‡ºçš„ JSON æ–‡ä»¶åŠ è½½æ¶ˆæ¯"""
    if not os.path.exists(TG_DATA_FILE):
        return []
    
    items = []
    with open(TG_DATA_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
        messages = data.get("messages", [])
        channel_name = data.get("name", "Unknown")
        channel_id = data.get("id", "")
        channel_type = data.get("type", "")
        channel_username = data.get("username", "")  # å°è¯•è·å–ç”¨æˆ·å
        
        for msg in messages:
            # åªå¤„ç†æ™®é€šæ¶ˆæ¯ï¼Œè·³è¿‡æœåŠ¡æ¶ˆæ¯
            if msg.get("type") != "message":
                continue
            
            text = extract_text_from_message(msg.get("text", ""))
            if not text.strip():
                continue
            
            message_id = msg.get("id", 0)
            
            # ç”Ÿæˆ Telegram æ¶ˆæ¯é“¾æ¥
            # å¯¹äºå…¬å¼€é¢‘é“ä¸”æœ‰ç”¨æˆ·å: https://t.me/{username}/{message_id}
            # å¯¹äºç§æœ‰é¢‘é“æˆ–æ— ç”¨æˆ·å: https://t.me/c/-100{channel_id}/{message_id}
            tg_link = ""
            if channel_id and message_id:
                # ä¼˜å…ˆä½¿ç”¨é…ç½®çš„ç”¨æˆ·å
                username_to_use = TG_CHANNEL_USERNAME.strip() if TG_CHANNEL_USERNAME else (channel_username.strip() if channel_username else "")
                
                # å¦‚æœ channel_id æ˜¯å­—ç¬¦ä¸²ä¸”ä»¥ "channel" å¼€å¤´ï¼Œæå–æ•°å­—éƒ¨åˆ†
                if isinstance(channel_id, str) and channel_id.startswith("channel"):
                    channel_id = channel_id.replace("channel", "")
                
                # å¦‚æœæœ‰ç”¨æˆ·åï¼Œä½¿ç”¨å…¬å¼€é¢‘é“æ ¼å¼
                if username_to_use:
                    # ç§»é™¤ @ ç¬¦å·ï¼ˆå¦‚æœæœ‰ï¼‰
                    username = username_to_use.replace("@", "").strip()
                    tg_link = f"https://t.me/{username}/{message_id}"
                else:
                    # ä½¿ç”¨ç§æœ‰é¢‘é“æ ¼å¼ï¼Œéœ€è¦ -100 å‰ç¼€
                    try:
                        channel_id_int = int(channel_id)
                        # Telegram ç§æœ‰é¢‘é“ ID éœ€è¦è½¬æ¢ä¸º -100{id} æ ¼å¼
                        tg_link = f"https://t.me/c/-100{channel_id_int}/{message_id}"
                    except (ValueError, TypeError):
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨
                        tg_link = f"https://t.me/c/{channel_id}/{message_id}"
            
            # æå–æ¶ˆæ¯å†…å®¹ä¸­çš„é“¾æ¥ï¼ˆä»å®ä½“ä¸­æå–ï¼‰
            content_urls = []
            text_entities = msg.get("text_entities", [])
            for entity in text_entities:
                if entity.get("type") == "link":
                    url = entity.get("text", "")
                    if url and not should_exclude_url(url) and url not in content_urls:
                        content_urls.append(url)
            
            # å¦‚æœæ²¡æœ‰ä» text_entities æ‰¾åˆ°ï¼Œä» text å­—æ®µä¸­æå–
            if not content_urls:
                text_field = msg.get("text", "")
                if isinstance(text_field, list):
                    for item in text_field:
                        if isinstance(item, dict) and item.get("type") == "link":
                            url = item.get("text", "")
                            if url and not should_exclude_url(url) and url not in content_urls:
                                content_urls.append(url)
            
            # ä»çº¯æ–‡æœ¬ä¸­æå– URLï¼ˆè¡¥å……æå–ï¼Œå·²åŒ…å«è¿‡æ»¤ï¼‰
            urls_from_text = extract_urls_from_text(text)
            for url in urls_from_text:
                if url not in content_urls:
                    content_urls.append(url)
            
            item = {
                "source": "tg",
                "type": "post",  # Telegram å¸–å­
                "title": channel_name,
                "content": text,
                "url": content_urls[0] if content_urls else "",  # ç¬¬ä¸€ä¸ªé“¾æ¥ï¼ˆå‘åå…¼å®¹ï¼‰
                "urls": content_urls,  # æ‰€æœ‰é“¾æ¥åˆ—è¡¨
                "tg_link": tg_link,  # Telegram æ¶ˆæ¯é“¾æ¥
                "date": msg.get("date", ""),
                "id": message_id
            }
            items.append(item)
    
    return items


def load_jsonl_items() -> List[Dict[str, Any]]:
    """ä» JSONL æ–‡ä»¶åŠ è½½æ•°æ®"""
    if not os.path.exists(DATA_FILE):
        return []
    
    items = []
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                items.append(json.loads(line))
            except json.JSONDecodeError:
                continue
    return items


def load_all_items() -> List[Dict[str, Any]]:
    """åŠ è½½æ‰€æœ‰æ•°æ®æº"""
    items = []
    
    # ä¼˜å…ˆä» JSONL åŠ è½½ï¼ˆç»Ÿä¸€æ•°æ®æºï¼‰
    jsonl_items = load_jsonl_items()
    if jsonl_items:
        items.extend(jsonl_items)
    else:
        # å¦‚æœ JSONL ä¸ºç©ºï¼Œä» Telegram JSON åŠ è½½ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
        tg_items = load_tg_messages()
        items.extend(tg_items)
    
    # å»é‡ï¼ˆåŸºäº IDï¼‰
    seen_ids = set()
    unique_items = []
    for item in items:
        item_id = item.get("id", 0)
        if item_id and item_id not in seen_ids:
            seen_ids.add(item_id)
            unique_items.append(item)
    
    return unique_items


def search_items(items: List[Dict[str, Any]], query: str) -> List[Dict[str, Any]]:
    """æœç´¢å†…å®¹"""
    if not query:
        return []
    
    q = query.lower()
    results = []
    
    for item in items:
        # æœç´¢æ ‡é¢˜å’Œå†…å®¹
        title = item.get("title", "").lower()
        content = item.get("content", "").lower()
        
        if q in title or q in content:
            results.append(item)
    
    return results


def format_result(item: Dict[str, Any], index: int) -> str:
    """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
    source = item.get("source", "unknown")
    title = item.get("title", "")
    content = item.get("content", "")
    url = item.get("url", "")
    date = item.get("date", "")
    
    # æˆªæ–­è¿‡é•¿çš„å†…å®¹
    content_preview = content[:300] + "..." if len(content) > 300 else content
    
    result = f"{index}. [{source.upper()}] {title}\n"
    if date:
        result += f"   æ—¥æœŸ: {date}\n"
    result += f"   {content_preview}\n"
    if url:
        result += f"   é“¾æ¥: {url}\n"
    
    return result


if __name__ == "__main__":
    print("æ­£åœ¨åŠ è½½æ•°æ®...")
    items = load_all_items()
    print(f"å·²è½½å…¥ {len(items)} æ¡å†…å®¹")
    print("ï¼ˆè¾“å…¥ç©ºè¡Œé€€å‡ºï¼‰\n")
    
    while True:
        query = input("ğŸ” æœç´¢: ").strip()
        if not query:
            print("å†è§ï¼")
            break
        
        results = search_items(items, query)
        print(f"\næ‰¾åˆ° {len(results)} æ¡ç»“æœï¼š\n")
        
        if results:
            for i, item in enumerate(results, start=1):
                print("-" * 60)
                print(format_result(item, i))
        else:
            print("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœ")
        
        print()
